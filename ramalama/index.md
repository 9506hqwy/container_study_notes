# RamaLama

```{toctree}
install
run
mcp
```

## 参考

- [ramalama](https://github.com/containers/ramalama)
- [How RamaLama makes working with AI models boring](https://developers.redhat.com/articles/2024/11/22/how-ramalama-makes-working-ai-models-boring)
- [How RamaLama runs AI models in isolation by default](https://developers.redhat.com/articles/2025/02/20/how-ramalama-runs-ai-models-isolation-default)
- [How to run OpenAI's gpt-oss models locally with RamaLama](https://developers.redhat.com/articles/2025/09/09/how-run-openais-gpt-oss-models-locally-ramalama)
- [Run containerized AI models locally with RamaLama](https://www.redhat.com/ja/blog/run-containerized-ai-models-locally-ramalama)
